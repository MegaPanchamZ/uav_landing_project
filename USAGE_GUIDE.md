# ðŸš UAV Landing System - Plug & Play Guide

A complete **neuro-symbolic UAV landing detection system** combining fine-tuned deep learning with rule-based reasoning for safe, reliable autonomous landing.

##  Quick Start (Plug & Play)

### Installation
```bash
# Clone the repository
git clone https://github.com/SOMEGUYSGITHUB_PROBABALY_MINE_MEGAPANCHAMZ/uav_landing_project.git
cd uav_landing_project

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage
```python
from uav_landing_system import UAVLandingSystem
import cv2

# 1. Initialize system (loads fine-tuned model)
system = UAVLandingSystem()

# 2. Load your UAV image
image = cv2.imread("your_uav_image.jpg")

# 3. Process for landing detection
result = system.process_frame(image, altitude=5.0, enable_tracing=True)

# 4. Get results
print(f"Status: {result.status}")                    # TARGET_ACQUIRED/NO_TARGET/UNSAFE
print(f"Confidence: {result.confidence:.3f}")        # 0.0-1.0 confidence score
print(f"Processing time: {result.processing_time:.1f}ms")

# 5. Access landing coordinates (if target found)
if result.target_pixel:
    print(f"Landing target: {result.target_pixel}")  # (x, y) in image
    print(f"World coordinates: {result.target_world}") # (x, y) in meters
    
# 6. Get flight commands
print(f"Forward velocity: {result.forward_velocity:.3f} m/s")
print(f"Right velocity: {result.right_velocity:.3f} m/s") 
print(f"Descent rate: {result.descent_rate:.3f} m/s")
```

### Convenience Function (One-liner)
```python
from uav_landing_system import process_image_for_landing
import cv2

# Process single image
image = cv2.imread("uav_frame.jpg")
result = process_image_for_landing(image, altitude=8.0, enable_tracing=True)

print(f"Landing decision: {result.status} (confidence: {result.confidence:.3f})")
print(f"Explanation: {result.decision_explanation}")
```

## ðŸ” Resolution Configuration (Quality vs Speed Trade-offs)

The UAV Landing System now supports configurable input resolution for optimal quality vs speed balance:

### Available Resolutions
- **256Ã—256**: Ultra-fast processing (~80-127 FPS) - Best for racing drones and real-time flight
- **512Ã—512**: Balanced quality/speed (~20-60 FPS) - **[RECOMMENDED]** for general use
- **768Ã—768**: High quality (~8-25 FPS) - Best for precision landing and mapping
- **1024Ã—1024**: Maximum quality (~3-12 FPS) - Best for research and analysis

### Resolution Configuration Examples
```python
from uav_landing_system import UAVLandingSystem
import cv2

# Ultra-fast for racing drones (256Ã—256)
racing_system = UAVLandingSystem(input_resolution=(256, 256))

# Balanced for general use (512Ã—512) - DEFAULT
general_system = UAVLandingSystem(input_resolution=(512, 512))

# High quality for precision landing (768Ã—768)
precision_system = UAVLandingSystem(input_resolution=(768, 768))

# Maximum quality for research (1024Ã—1024)
research_system = UAVLandingSystem(input_resolution=(1024, 1024))

# Test image
image = cv2.imread("uav_image.jpg")

# Compare performance
for name, system in [("Racing", racing_system), 
                    ("General", general_system),
                    ("Precision", precision_system)]:
    result = system.process_frame(image, altitude=5.0)
    print(f"{name}: {result.processing_time:.1f}ms, confidence: {result.confidence:.3f}")
```

### Convenience Function with Resolution
```python
from uav_landing_system import process_image_for_landing

# Ultra-fast processing
result_fast = process_image_for_landing(
    image, altitude=5.0, 
    input_resolution=(256, 256)  # Ultra-fast
)

# High-quality processing  
result_hq = process_image_for_landing(
    image, altitude=5.0,
    input_resolution=(768, 768)  # High quality
)

print(f"Fast: {result_fast.processing_time:.1f}ms")
print(f"HQ: {result_hq.processing_time:.1f}ms")
```

### Adaptive Resolution Selection
```python
def select_resolution_for_scenario(altitude, velocity, mission_type):
    """Smart resolution selection based on flight conditions"""
    
    if mission_type == "racing" or velocity > 5.0:
        return (256, 256)  # Speed priority
    elif mission_type == "research" or velocity < 1.0:
        return (1024, 1024)  # Quality priority  
    elif altitude < 2.0:  # Precision landing
        return (768, 768)  # High quality for precision
    else:
        return (512, 512)  # Balanced default

# Usage
resolution = select_resolution_for_scenario(
    altitude=1.5, velocity=0.3, mission_type="precision"
)
system = UAVLandingSystem(input_resolution=resolution)
```

### Resolution Performance Guide
| Resolution | Processing Time | FPS Range | Quality | Best Use Cases |
|------------|----------------|-----------|---------|----------------|
| 256Ã—256    | ~2-15ms       | 80-127    | Basic   | Racing, Real-time flight |
| 512Ã—512    | ~15-50ms      | 20-60     | Good    | General UAV operations |  
| 768Ã—768    | ~40-120ms     | 8-25      | High    | Precision landing, Mapping |
| 1024Ã—1024  | ~80-300ms     | 3-12      | Maximum | Research, Offline analysis |

ðŸ’¡ **Recommendation**: Start with 512Ã—512 (balanced) and adjust based on your performance requirements!

## ðŸ§  Neuro-Symbolic Reasoning with Traceability

### Full Traceability Example
```python
from uav_landing_system import UAVLandingSystem

system = UAVLandingSystem(enable_logging=True)

# Process with full traceability
result = system.process_frame(image, altitude=5.0, enable_tracing=True)

# Access neural network insights
if result.trace:
    print("ðŸ§  NEURAL COMPONENT:")
    print(f"  Classes detected: {result.trace.neural_classes_detected}")
    print(f"  Neural confidence: {result.trace.neural_confidence:.3f}")
    print(f"  Class distribution: {result.trace.neural_class_distribution}")
    
    print("\nðŸ”¬ SYMBOLIC REASONING:")
    print(f"  Landing candidates: {result.trace.symbolic_candidates_found}")
    print(f"  Rules applied: {result.trace.symbolic_rules_applied}")
    print(f"  Safety checks: {result.trace.symbolic_safety_checks}")
    
    print("\n INTEGRATION:")
    print(f"  Final score: {result.trace.neuro_symbolic_score:.3f}")
    print(f"  Decision weights: {result.trace.decision_weights}")
    
    print("\nâš ï¸ RISK ASSESSMENT:")
    print(f"  Risk level: {result.trace.risk_level}")
    print(f"  Risk factors: {result.trace.risk_factors}")
    print(f"  Recommendations: {result.trace.safety_recommendations}")
    
    print(f"\nðŸ“Š PERFORMANCE:")
    print(f"  Processing time: {result.trace.total_processing_time:.1f}ms")
    print(f"  Inference FPS: {result.trace.inference_fps:.1f}")

# Export trace for analysis
trace_dict = result.trace.to_dict()
print("JSON export available for detailed analysis")
```

### Batch Processing with Logging
```python
from uav_landing_system import UAVLandingSystem
import json

system = UAVLandingSystem(enable_logging=True)
traces = []

# Process multiple frames
for frame_path in uav_frames:
    image = cv2.imread(frame_path)
    result = system.process_frame(image, altitude=6.0, enable_tracing=True)
    
    if result.trace:
        traces.append(result.trace)
    
    print(f"{frame_path}: {result.status} ({result.confidence:.3f})")

# Save comprehensive trace log
system.save_trace_log(traces, "mission_analysis.json")
print("ðŸ“„ Complete mission analysis saved to mission_analysis.json")
```

## ðŸ”§ Configuration

### Custom Configuration
```python
# Create custom config file: config.json
{
    "neural_weight": 0.4,           // Neural network influence (0.0-1.0)
    "symbolic_weight": 0.6,         // Symbolic reasoning influence (0.0-1.0)
    "safety_threshold": 0.3,        // Minimum confidence for safe landing
    "enable_temporal_tracking": true,
    "max_tracking_history": 10
}

# Initialize with custom config
system = UAVLandingSystem(
    model_path="trained_models/ultra_fast_uav_landing.onnx",
    config_path="config.json",
    enable_logging=True,
    log_level="DEBUG"
)
```

### Model Paths
```python
# Use different model versions
system_v1 = UAVLandingSystem("trained_models/ultra_stage1_best.pth")  # PyTorch
system_v2 = UAVLandingSystem("trained_models/ultra_stage2_best.pth")  # PyTorch  
system_onnx = UAVLandingSystem("trained_models/ultra_fast_uav_landing.onnx")  # ONNX (recommended)
```

## ðŸ“Š Understanding Results

### Status Types
- **`TARGET_ACQUIRED`**: Safe landing zone found, proceed with landing
- **`NO_TARGET`**: No suitable landing zones detected, search alternative area
- **`UNSAFE`**: Landing zone detected but deemed unsafe, abort landing
- **`ERROR`**: Processing error occurred

### Confidence Interpretation
- **0.8-1.0**: High confidence, very safe to land
- **0.5-0.8**: Medium confidence, proceed with caution  
- **0.3-0.5**: Low confidence, consider altitude adjustment
- **0.0-0.3**: Very low confidence, avoid landing

### Risk Levels (from traceability)
- **`LOW`**: All safety checks passed, optimal landing conditions
- **`MEDIUM`**: Some concerns present, proceed with monitoring
- **`HIGH`**: Significant safety concerns, abort recommended

##  Real-World Usage Examples

### Drone Racing/Competition
```python
# High-speed processing for racing drones
system = UAVLandingSystem(enable_logging=False)  # Minimal logging for speed

for frame in video_stream:
    result = system.process_frame(frame, altitude=current_altitude)
    
    if result.status == "TARGET_ACQUIRED" and result.confidence > 0.7:
        # Execute landing sequence
        send_landing_commands(result.forward_velocity, result.right_velocity, result.descent_rate)
    else:
        # Continue search pattern
        continue_search_pattern()
```

### Research & Development  
```python
# Full analysis with detailed logging
system = UAVLandingSystem(
    enable_logging=True,
    log_level="DEBUG"
)

research_data = []
for test_image in research_dataset:
    result = system.process_frame(test_image, altitude=5.0, enable_tracing=True)
    
    # Collect detailed metrics
    research_data.append({
        'image_id': test_image.name,
        'result': result.status,
        'confidence': result.confidence,
        'neural_breakdown': result.confidence_breakdown,
        'processing_time': result.processing_time,
        'trace': result.trace.to_dict() if result.trace else None
    })

# Export for research analysis
with open("research_results.json", "w") as f:
    json.dump(research_data, f, indent=2)
```

### Production Deployment
```python
# Production-ready error handling
import logging

class ProductionUAVLanding:
    def __init__(self):
        self.system = UAVLandingSystem(
            model_path="models/production_model.onnx",
            enable_logging=True,
            log_level="WARNING"  # Only important messages
        )
        self.logger = logging.getLogger("UAV_Production")
    
    def safe_landing_check(self, image, altitude, max_retries=3):
        for attempt in range(max_retries):
            try:
                result = self.system.process_frame(image, altitude, enable_tracing=True)
                
                # Production safety checks
                if result.status == "ERROR":
                    self.logger.error(f"Processing error on attempt {attempt + 1}")
                    continue
                    
                if result.trace and result.trace.risk_level == "HIGH":
                    self.logger.warning(f"High risk landing detected: {result.trace.safety_recommendations}")
                    return None
                
                if result.confidence < 0.5:
                    self.logger.warning(f"Low confidence: {result.confidence:.3f}")
                    continue
                
                return result
                
            except Exception as e:
                self.logger.error(f"Landing check failed: {e}")
                continue
        
        return None  # All attempts failed

# Usage
landing_system = ProductionUAVLanding()
landing_decision = landing_system.safe_landing_check(camera_frame, current_altitude)

if landing_decision and landing_decision.status == "TARGET_ACQUIRED":
    execute_landing(landing_decision)
else:
    abort_landing_sequence()
```

## ðŸ”¬ Model Performance Specifications

### Fine-Tuned Model Details
- **Model**: BiSeNetV2 with custom UAV landing head
- **Input**: 256Ã—256 RGB images  
- **Output**: 4-class semantic segmentation (Background, Suitable, Marginal, Unsuitable)
- **Size**: 1.3MB ONNX model
- **Speed**: 7-127 FPS (depending on hardware)
- **Training**: Multi-stage fine-tuning (CITYSCAPES â†’ UDD â†’ DRONEDEPLOY)

### Neuro-Symbolic Architecture
- **Neural Component**: Deep semantic segmentation (40% weight)
- **Symbolic Component**: Rule-based safety reasoning (60% weight)  
- **Integration**: Weighted decision fusion with safety overrides
- **Traceability**: Complete decision path recording for explainability

### Tested Performance
- **Real UDD Dataset**: Validated on actual UAV imagery
- **Processing Time**: 330-530ms on high-res images (2160Ã—4096)
- **Risk Assessment**: Successfully identifies unsafe landing conditions
- **Confidence Calibration**: Realistic confidence scores for real-world imagery

## ðŸš€ Advanced Features

### Custom Neural Networks
```python
# Use your own trained model
system = UAVLandingSystem(model_path="my_custom_model.onnx")
```

### Real-time Video Processing
```python
import cv2

system = UAVLandingSystem()
video = cv2.VideoCapture("uav_video.mp4")

while video.isOpened():
    ret, frame = video.read()
    if not ret:
        break
    
    result = system.process_frame(frame, altitude=estimate_altitude(frame))
    
    # Overlay results on frame
    if result.target_pixel:
        cv2.circle(frame, result.target_pixel, 20, (0, 255, 0), 3)
        cv2.putText(frame, f"{result.status}: {result.confidence:.2f}", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    cv2.imshow("UAV Landing Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

## ðŸ“š Additional Resources

- **Training Documentation**: `docs/TRAINING.md` - How the model was fine-tuned
- **API Reference**: `docs/API.md` - Complete class and method documentation  
- **Dataset Information**: `docs/DATASETS.md` - Training data specifications
- **Architecture Details**: `docs/ARCHITECTURE.md` - System design and reasoning

## ðŸ§ª Testing

Run comprehensive tests:
```bash
# Quick functionality test
python tests/quick_test.py

# Real model test with ONNX
python tests/test_real_model.py

# Full system validation
python tests/test_system.py

# Neuro-symbolic reasoning test with UDD dataset
python tests/integration/test_udd_neuro_symbolic.py
```

##  Ready to Deploy!

Your UAV landing system is now production-ready with:
-  **Plug & Play Interface**: Simple integration into any UAV system
-  **Neuro-Symbolic Intelligence**: Best of neural networks + rule-based reasoning  
-  **Full Traceability**: Complete decision path logging and explainability
-  **Safety-First Design**: Risk assessment and abort mechanisms
-  **Real-World Validated**: Tested on actual UAV imagery
-  **Production Optimized**: Error handling, logging, and performance monitoring

Start landing safely with just 3 lines of code! ðŸšðŸŽ¯
